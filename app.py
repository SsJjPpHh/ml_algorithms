import streamlit as st
import pandas as pd
import numpy as np
from src.data_utils import *
from src.ml_algorithms import ml_algorithms
from src.plotting import data_visualizer, model_visualizer
from src.stats_utils import statistical_analyzer
from src.interpretability import model_interpreter
import plotly.express as px
import plotly.graph_objects as go

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="åŒ»å­¦æ•°æ®åˆ†æå¹³å°",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #ff7f0e;
        margin-top: 1rem;
        margin-bottom: 1rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .success-box {
        background-color: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #c3e6cb;
    }
    .warning-box {
        background-color: #fff3cd;
        color: #856404;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #ffeaa7;
    }
</style>
""", unsafe_allow_html=True)

def main():
    # ä¸»æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸ¥ åŒ»å­¦æ•°æ®åˆ†æå¹³å°</h1>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("ğŸ”§ æ§åˆ¶é¢æ¿")
        
        # æ•°æ®åŠ è½½é€‰é¡¹
        st.subheader("ğŸ“Š æ•°æ®åŠ è½½")
        data_source = st.radio(
            "é€‰æ‹©æ•°æ®æº",
            ["ä¸Šä¼ æ–‡ä»¶", "ä½¿ç”¨ç¤ºä¾‹æ•°æ®"]
        )
        
        # åˆå§‹åŒ–session state
        if 'data_loaded' not in st.session_state:
            st.session_state.data_loaded = False
        if 'df' not in st.session_state:
            st.session_state.df = None
        if 'model_trained' not in st.session_state:
            st.session_state.model_trained = False
        if 'trained_model' not in st.session_state:
            st.session_state.trained_model = None
    
    # æ•°æ®åŠ è½½éƒ¨åˆ†
    if data_source == "ä¸Šä¼ æ–‡ä»¶":
        uploaded_file = st.file_uploader(
            "é€‰æ‹©CSVæˆ–Excelæ–‡ä»¶",
            type=['csv', 'xlsx', 'xls'],
            help="æ”¯æŒCSVå’ŒExcelæ ¼å¼æ–‡ä»¶"
        )
        
        if uploaded_file is not None:
            df = load_data(uploaded_file)
            if df is not None:
                st.session_state.df = df
                st.session_state.data_loaded = True
    
    else:  # ä½¿ç”¨ç¤ºä¾‹æ•°æ®
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ç”Ÿæˆåˆ†ç±»æ•°æ®"):
                df = generate_sample_data("classification")
                st.session_state.df = df
                st.session_state.data_loaded = True
                st.success("åˆ†ç±»ç¤ºä¾‹æ•°æ®ç”ŸæˆæˆåŠŸï¼")
        
        with col2:
            if st.button("ç”Ÿæˆå›å½’æ•°æ®"):
                df = generate_sample_data("regression")
                st.session_state.df = df
                st.session_state.data_loaded = True
                st.success("å›å½’ç¤ºä¾‹æ•°æ®ç”ŸæˆæˆåŠŸï¼")
    
    # å¦‚æœæ•°æ®å·²åŠ è½½ï¼Œæ˜¾ç¤ºä¸»è¦åŠŸèƒ½
    if st.session_state.data_loaded and st.session_state.df is not None:
        df = st.session_state.df
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        tab_data, tab_ml, tab_stats, tab_interpret = st.tabs([
            "ğŸ“Š æ•°æ®æ¦‚è§ˆ", 
            "ğŸ¤– æœºå™¨å­¦ä¹ ", 
            "ğŸ“ˆ ç»Ÿè®¡åˆ†æ", 
            "ğŸ” æ¨¡å‹è§£é‡Š"
        ])
        
        # æ•°æ®æ¦‚è§ˆæ ‡ç­¾é¡µ
        with tab_data:
            show_data_overview(df)
        
        # æœºå™¨å­¦ä¹ æ ‡ç­¾é¡µ
        with tab_ml:
            show_machine_learning(df)
        
        # ç»Ÿè®¡åˆ†ææ ‡ç­¾é¡µ
        with tab_stats:
            show_statistical_analysis(df)
        
        # æ¨¡å‹è§£é‡Šæ ‡ç­¾é¡µ
        with tab_interpret:
            show_model_interpretation(df)

def show_data_overview(df):
    """æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ"""
    st.markdown('<h2 class="sub-header">ğŸ“Š æ•°æ®æ¦‚è§ˆ</h2>', unsafe_allow_html=True)
    
    # åŸºæœ¬ä¿¡æ¯
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æ•°æ®è¡Œæ•°", df.shape[0])
    with col2:
        st.metric("æ•°æ®åˆ—æ•°", df.shape[1])
    with col3:
        st.metric("ç¼ºå¤±å€¼", df.isnull().sum().sum())
    with col4:
        st.metric("é‡å¤è¡Œ", df.duplicated().sum())
    
    # æ•°æ®é¢„è§ˆ
    st.subheader("ğŸ” æ•°æ®é¢„è§ˆ")
    st.dataframe(df.head(10), use_container_width=True)
    
    # æ•°æ®ä¿¡æ¯
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“‹ æ•°æ®ä¿¡æ¯")
        info_dict = get_data_info(df)
        for key, value in info_dict.items():
            if isinstance(value, list):
                st.write(f"**{key}**: {', '.join(value) if value else 'æ— '}")
            else:
                st.write(f"**{key}**: {value}")
    
    with col2:
        st.subheader("âŒ ç¼ºå¤±å€¼è¯¦æƒ…")
        missing_info = get_missing_info(df)
        if not missing_info.empty:
            st.dataframe(missing_info)
        else:
            st.success("æ•°æ®æ— ç¼ºå¤±å€¼ï¼")
    
    # æ•°æ®å¯è§†åŒ–
    st.subheader("ğŸ“ˆ æ•°æ®å¯è§†åŒ–")
    
    viz_col1, viz_col2 = st.columns(2)
    
    with viz_col1:
        # æ•°æ®æ¦‚è§ˆå›¾
        data_visualizer.plot_data_overview(df)
    
    with viz_col2:
        # æ•°å€¼å˜é‡åˆ†å¸ƒ
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if numeric_cols:
            selected_cols = st.multiselect(
                "é€‰æ‹©è¦å¯è§†åŒ–çš„æ•°å€¼å˜é‡",
                numeric_cols,
                default=numeric_cols[:3]
            )
            
            plot_type = st.selectbox("é€‰æ‹©å›¾è¡¨ç±»å‹", ["histogram", "boxplot"])
            
            if selected_cols:
                data_visualizer.plot_distribution(df, selected_cols, plot_type)
    
    # ç›¸å…³æ€§åˆ†æ
    if len(df.select_dtypes(include=[np.number]).columns) >= 2:
        st.subheader("ğŸ”— ç›¸å…³æ€§åˆ†æ")
        corr_method = st.selectbox("é€‰æ‹©ç›¸å…³æ€§æ–¹æ³•", ["pearson", "spearman", "kendall"])
        corr_matrix = data_visualizer.plot_correlation_matrix(df, corr_method)

def show_machine_learning(df):
    """æ˜¾ç¤ºæœºå™¨å­¦ä¹ åŠŸèƒ½"""
    st.markdown('<h2 class="sub-header">ğŸ¤– æœºå™¨å­¦ä¹ </h2>', unsafe_allow_html=True)
    
    # ä»»åŠ¡é…ç½®
    st.subheader("âš™ï¸ ä»»åŠ¡é…ç½®")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        task_type = st.selectbox(
            "é€‰æ‹©ä»»åŠ¡ç±»å‹",
            ["åˆ†ç±»", "å›å½’", "èšç±»"]
        )
    
    with col2:
        target_col = None
        if task_type in ["åˆ†ç±»", "å›å½’"]:
            target_col = st.selectbox(
                "é€‰æ‹©ç›®æ ‡å˜é‡",
                df.columns.tolist()
            )
    
    with col3:
        if task_type in ["åˆ†ç±»", "å›å½’"]:
            test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.5, 0.2, 0.05)
    
    # ç®—æ³•é€‰æ‹©å’Œå‚æ•°é…ç½®
    if task_type in ml_algorithms.algorithms:
        st.subheader("ğŸ”§ ç®—æ³•é€‰æ‹©")
        
        algorithm_name = st.selectbox(
            "é€‰æ‹©ç®—æ³•",
            list(ml_algorithms.algorithms[task_type].keys())
        )
        
        # å‚æ•°é…ç½®
        st.subheader("âš™ï¸ å‚æ•°é…ç½®")
        params = ml_algorithms.get_algorithm_params(task_type, algorithm_name)
        
        # æ•°æ®é¢„å¤„ç†é€‰é¡¹
        st.subheader("ğŸ”„ æ•°æ®é¢„å¤„ç†")
        preprocess_col1, preprocess_col2 = st.columns(2)
        
        with preprocess_col1:
            handle_missing = st.selectbox(
                "ç¼ºå¤±å€¼å¤„ç†",
                ["mean", "median", "most_frequent", "constant"]
            )
        
        with preprocess_col2:
            scale_features = st.checkbox("ç‰¹å¾æ ‡å‡†åŒ–", value=True)
        
        # è®­ç»ƒæ¨¡å‹
        if st.button("ğŸš€ å¼€å§‹è®­ç»ƒ", type="primary"):
            if task_type in ["åˆ†ç±»", "å›å½’"] and target_col:
                with st.spinner("æ­£åœ¨è®­ç»ƒæ¨¡å‹..."):
                    # æ•°æ®é¢„å¤„ç†
                    X_train, X_test, y_train, y_test = preprocess_data(
                        df, target_col, task_type, test_size, 
                        handle_missing, scale_features
                    )
                    
                    if X_train is not None:
                        # åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
                        model = ml_algorithms.create_model(task_type, algorithm_name, params)
                        trained_model, success, message = ml_algorithms.train_model(model, X_train, y_train)
                        
                        if success:
                            st.success(message)
                            st.session_state.trained_model = trained_model
                            st.session_state.model_trained = True
                            st.session_state.X_train = X_train
                            st.session_state.X_test = X_test
                            st.session_state.y_train = y_train
                            st.session_state.y_test = y_test
                            st.session_state.task_type = task_type
                            st.session_state.algorithm_name = algorithm_name
                            
                            # æ¨¡å‹è¯„ä¼°
                            st.subheader("ğŸ“Š æ¨¡å‹è¯„ä¼°")
                            
                            if task_type == "åˆ†ç±»":
                                metrics, y_pred, y_pred_proba = ml_algorithms.evaluate_classification(
                                    trained_model, X_test, y_test
                                )
                                
                                if metrics:
                                    # æ˜¾ç¤ºè¯„ä¼°æŒ‡æ ‡
                                    metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)
                                    
                                    with metric_col1:
                                        st.metric("å‡†ç¡®ç‡", f"{metrics['accuracy']:.4f}")
                                    with metric_col2:
                                        st.metric("ç²¾ç¡®ç‡", f"{metrics['precision']:.4f}")
                                    with metric_col3:
                                        st.metric("å¬å›ç‡", f"{metrics['recall']:.4f}")
                                    with metric_col4:
                                        st.metric("F1åˆ†æ•°", f"{metrics['f1_score']:.4f}")
                                    
                                    if 'roc_auc' in metrics:
                                        st.metric("ROC AUC", f"{metrics['roc_auc']:.4f}")
                                    
                                    # å¯è§†åŒ–ç»“æœ
                                    viz_col1, viz_col2 = st.columns(2)
                                    
                                    with viz_col1:
                                        # æ··æ·†çŸ©é˜µ
                                        model_visualizer.plot_confusion_matrix(y_test, y_pred)
                                    
                                    with viz_col2:
                                        # ROCæ›²çº¿
                                        if y_pred_proba is not None and len(np.unique(y_test)) == 2:
                                            model_visualizer.plot_roc_curve(y_test, y_pred_proba)
                                    
                                    # ç‰¹å¾é‡è¦æ€§
                                    feature_names = X_train.columns.tolist()
                                    model_visualizer.plot_feature_importance(trained_model, feature_names)
                            
                            elif task_type == "å›å½’":
                                metrics, y_pred = ml_algorithms.evaluate_regression(trained_model, X_test, y_test)
                                
                                if metrics:
                                    # æ˜¾ç¤ºè¯„ä¼°æŒ‡æ ‡
                                    metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)
                                    
                                    with metric_col1:
                                        st.metric("MSE", f"{metrics['mse']:.4f}")
                                    with metric_col2:
                                        st.metric("RMSE", f"{metrics['rmse']:.4f}")
                                    with metric_col3:
                                        st.metric("MAE", f"{metrics['mae']:.4f}")
                                    with metric_col4:
                                        st.metric("RÂ²åˆ†æ•°", f"{metrics['r2_score']:.4f}")
                                    
                                    # å›å½’ç»“æœå¯è§†åŒ–
                                    model_visualizer.plot_regression_results(y_test, y_pred)
                                    
                                    # ç‰¹å¾é‡è¦æ€§
                                    feature_names = X_train.columns.tolist()
                                    model_visualizer.plot_feature_importance(trained_model, feature_names)
                        else:
                            st.error(message)
            
            elif task_type == "èšç±»":
                with st.spinner("æ­£åœ¨è¿›è¡Œèšç±»åˆ†æ..."):
                    # èšç±»ä¸éœ€è¦ç›®æ ‡å˜é‡
                    numeric_cols = df.select_dtypes(include=[np.number]).columns
                    if len(numeric_cols) == 0:
                        st.error("èšç±»åˆ†æéœ€è¦æ•°å€¼å‹å˜é‡")
                    else:
                        X = df[numeric_cols].fillna(df[numeric_cols].mean())
                        
                        # ç‰¹å¾æ ‡å‡†åŒ–
                        if scale_features:
                            from sklearn.preprocessing import StandardScaler
                            scaler = StandardScaler()
                            X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)
                        
                        # åˆ›å»ºå’Œè®­ç»ƒèšç±»æ¨¡å‹
                        model = ml_algorithms.create_model(task_type, algorithm_name, params)
                        metrics, labels = ml_algorithms.evaluate_clustering(model, X)
                        
                        if metrics:
                            st.success("èšç±»åˆ†æå®Œæˆï¼")
                            
                            # æ˜¾ç¤ºèšç±»æŒ‡æ ‡
                            metric_col1, metric_col2 = st.columns(2)
                            with metric_col1:
                                st.metric("èšç±»æ•°é‡", metrics['n_clusters'])
                            with metric_col2:
                                if 'silhouette_score' in metrics:
                                    st.metric("è½®å»“ç³»æ•°", f"{metrics['silhouette_score']:.4f}")
                            
                            # èšç±»ç»“æœå¯è§†åŒ–
                            model_visualizer.plot_clustering_results(X, labels, algorithm_name)
                            
                            # ä¿å­˜èšç±»ç»“æœ
                            st.session_state.trained_model = model
                            st.session_state.model_trained = True
                            st.session_state.cluster_labels = labels
                            st.session_state.task_type = task_type
                            st.session_state.algorithm_name = algorithm_name

def show_statistical_analysis(df):
    """æ˜¾ç¤ºç»Ÿè®¡åˆ†æåŠŸèƒ½"""
    st.markdown('<h2 class="sub-header">ğŸ“ˆ ç»Ÿè®¡åˆ†æ</h2>', unsafe_allow_html=True)
    
    # æè¿°æ€§ç»Ÿè®¡
    st.subheader("ğŸ“Š æè¿°æ€§ç»Ÿè®¡")
    
    desc_col1, desc_col2 = st.columns(2)
    
    with desc_col1:
        group_col = st.selectbox(
            "åˆ†ç»„å˜é‡ (å¯é€‰)",
            [None] + df.columns.tolist(),
            key="desc_group"
        )
    
    with desc_col2:
        if st.button("ç”Ÿæˆæè¿°æ€§ç»Ÿè®¡"):
            desc_stats = statistical_analyzer.descriptive_stats(df, group_col)
            if desc_stats is not None:
                st.dataframe(desc_stats, use_container_width=True)
    
    st.divider()
    
    # å‡è®¾æ£€éªŒ
    st.subheader("ğŸ”¬ å‡è®¾æ£€éªŒ")
    
    test_type = st.selectbox(
        "é€‰æ‹©æ£€éªŒç±»å‹",
        ["æ­£æ€æ€§æ£€éªŒ", "ä¸¤ç»„æ¯”è¾ƒ", "å¤šç»„æ¯”è¾ƒ", "ç›¸å…³åˆ†æ", "å¡æ–¹æ£€éªŒ"]
    )
    
    if test_type == "æ­£æ€æ€§æ£€éªŒ":
        col1, col2 = st.columns(2)
        
        with col1:
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_cols:
                test_var = st.selectbox("é€‰æ‹©æ£€éªŒå˜é‡", numeric_cols)
                norm_test_type = st.selectbox("æ£€éªŒæ–¹æ³•", ["shapiro", "ks"])
        
        with col2:
            if st.button("è¿è¡Œæ­£æ€æ€§æ£€éªŒ"):
                if numeric_cols:
                    result = statistical_analyzer.normality_test(df[test_var], norm_test_type)
                    
                    if 'error' not in result:
                        st.write("**æ£€éªŒç»“æœ:**")
                        st.write(f"- æ£€éªŒæ–¹æ³•: {result['test']}")
                        st.write(f"- ç»Ÿè®¡é‡: {result['statistic']:.6f}")
                        st.write(f"- på€¼: {result['p_value']:.6f}")
                        st.write(f"- ç»“è®º: {result['interpretation']}")
                        
                        # å¯è§†åŒ–
                        fig = px.histogram(df, x=test_var, title=f"{test_var} åˆ†å¸ƒç›´æ–¹å›¾")
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.error(result['error'])
    
    elif test_type == "ä¸¤ç»„æ¯”è¾ƒ":
        col1, col2 = st.columns(2)
        
        with col1:
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
            
            if numeric_cols and categorical_cols:
                test_var = st.selectbox("æ•°å€¼å˜é‡", numeric_cols)
                group_var = st.selectbox("åˆ†ç»„å˜é‡", categorical_cols)
                test_method = st.selectbox("æ£€éªŒæ–¹æ³•", ["auto", "ttest", "mannwhitney"])
                paired = st.checkbox("é…å¯¹æ£€éªŒ")
        
        with col2:
            if st.button("è¿è¡Œä¸¤ç»„æ¯”è¾ƒ"):
                if numeric_cols and categorical_cols:
                    # æ£€æŸ¥åˆ†ç»„å˜é‡æ˜¯å¦åªæœ‰ä¸¤ä¸ªç»„
                    groups = df[group_var].dropna().unique()
                    if len(groups) != 2:
                        st.error("åˆ†ç»„å˜é‡å¿…é¡»æ°å¥½æœ‰ä¸¤ä¸ªç»„")
                    else:
                        group1_data = df[df[group_var] == groups[0]][test_var]
                        group2_data = df[df[group_var] == groups[1]][test_var]
                        
                        result = statistical_analyzer.two_sample_test(
                            group1_data, group2_data, test_method, paired
                        )
                        
                        if 'error' not in result:
                            st.write("**æ£€éªŒç»“æœ:**")
                            st.write(f"- æ£€éªŒæ–¹æ³•: {result['test']}")
                            st.write(f"- ç»Ÿè®¡é‡: {result['statistic']:.6f}")
                            st.write(f"- på€¼: {result['p_value']:.6f}")
                            
                            if 'mean_group1' in result:
                                st.write(f"- {groups[0]}ç»„å‡å€¼: {result['mean_group1']:.4f}")
                                st.write(f"- {groups[1]}ç»„å‡å€¼: {result['mean_group2']:.4f}")
                            
                            if 'effect_size' in result:
                                st.write(f"- æ•ˆåº”é‡ (Cohen's d): {result['effect_size']:.4f}")
                                st.write(f"- æ•ˆåº”é‡è§£é‡Š: {result['effect_interpretation']}")
                            
                            # å¯è§†åŒ–
                            fig = px.box(df, x=group_var, y=test_var, title=f"{test_var} æŒ‰ {group_var} åˆ†ç»„")
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.error(result['error'])
    
    elif test_type == "å¤šç»„æ¯”è¾ƒ":
        col1, col2 = st.columns(2)
        
        with col1:
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
            
            if numeric_cols and categorical_cols:
                dependent_var = st.selectbox("å› å˜é‡", numeric_cols)
                independent_var = st.selectbox("è‡ªå˜é‡", categorical_cols)
        
        with col2:
            if st.button("è¿è¡Œæ–¹å·®åˆ†æ"):
                if numeric_cols and categorical_cols:
                    result = statistical_analyzer.anova_test(df, dependent_var, independent_var)
                    
                    if 'error' not in result:
                        st.write("**ANOVAç»“æœ:**")
                        st.write(f"- Fç»Ÿè®¡é‡: {result['f_statistic']:.6f}")
                        st.write(f"- på€¼: {result['p_value']:.6f}")
                        
                        # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                        if 'detailed_results' in result:
                            st.write("**è¯¦ç»†ç»“æœ:**")
                            st.dataframe(result['detailed_results'])
                        
                        # äº‹åæ£€éªŒ
                        if 'posthoc_test' in result:
                            st.write("**äº‹åæ£€éªŒ (Tukey HSD):**")
                            st.dataframe(result['posthoc_test'])
                        
                        # å¯è§†åŒ–
                        fig = px.box(df, x=independent_var, y=dependent_var, 
                                   title=f"{dependent_var} æŒ‰ {independent_var} åˆ†ç»„")
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.error(result['error'])
    
    elif test_type == "ç›¸å…³åˆ†æ":
        col1, col2 = st.columns(2)
        
        with col1:
            corr_method = st.selectbox("ç›¸å…³æ–¹æ³•", ["pearson", "spearman", "kendall"])
        
        with col2:
            if st.button("è¿è¡Œç›¸å…³åˆ†æ"):
                result = statistical_analyzer.correlation_analysis(df, corr_method)
                
                if 'error' not in result:
                    st.write(f"**{corr_method.capitalize()} ç›¸å…³åˆ†æç»“æœ:**")
                    
                    # æ˜¾ç¤ºç›¸å…³ç³»æ•°çŸ©é˜µ
                    st.dataframe(result['correlation_matrix'].round(4))
                    
                    # æ˜¾ç¤ºå¸¦på€¼çš„ç›¸å…³ç»“æœ
                    if 'correlation_with_pvalues' in result:
                        st.write("**ç›¸å…³ç³»æ•°åŠæ˜¾è‘—æ€§:**")
                        st.dataframe(result['correlation_with_pvalues'].round(4))
                    
                    # çƒ­å›¾å¯è§†åŒ–
                    corr_matrix = result['correlation_matrix']
                    fig = px.imshow(
                        corr_matrix,
                        text_auto=True,
                        aspect="auto",
                        title=f"{corr_method.capitalize()} ç›¸å…³ç³»æ•°çƒ­å›¾",
                        color_continuous_scale='RdBu_r'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.error(result['error'])
    
    elif test_type == "å¡æ–¹æ£€éªŒ":
        col1, col2 = st.columns(2)
        
        with col1:
            categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
            
            if len(categorical_cols) >= 2:
                var1 = st.selectbox("å˜é‡1", categorical_cols)
                var2 = st.selectbox("å˜é‡2", [col for col in categorical_cols if col != var1])
        
        with col2:
            if st.button("è¿è¡Œå¡æ–¹æ£€éªŒ"):
                if len(categorical_cols) >= 2:
                    result = statistical_analyzer.chi_square_test(df, var1, var2)
                    
                    if 'error' not in result:
                        st.write("**å¡æ–¹æ£€éªŒç»“æœ:**")
                        st.write(f"- å¡æ–¹ç»Ÿè®¡é‡: {result['chi2_statistic']:.6f}")
                        st.write(f"- på€¼: {result['p_value']:.6f}")
                        st.write(f"- è‡ªç”±åº¦: {result['degrees_of_freedom']}")
                        st.write(f"- Cramer's V: {result['cramers_v']:.4f}")
                        
                        # åˆ—è”è¡¨
                        st.write("**åˆ—è”è¡¨:**")
                        st.dataframe(result['contingency_table'])
                        
                        # å¯è§†åŒ–
                        fig = px.density_heatmap(
                            df, x=var1, y=var2, 
                            title=f"{var1} vs {var2} åˆ—è”è¡¨çƒ­å›¾"
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.error(result['error'])
    
    st.divider()
    
    # å›å½’åˆ†æ
    st.subheader("ğŸ“Š å›å½’åˆ†æ")
    
    regression_type = st.selectbox("å›å½’ç±»å‹", ["çº¿æ€§å›å½’", "é€»è¾‘å›å½’"])
    
    col1, col2 = st.columns(2)
    
    with col1:
        all_cols = df.columns.tolist()
        dependent_var = st.selectbox("å› å˜é‡", all_cols, key="reg_dependent")
        
        available_vars = [col for col in all_cols if col != dependent_var]
        independent_vars = st.multiselect("è‡ªå˜é‡", available_vars, key="reg_independent")
    
    with col2:
        if st.button("è¿è¡Œå›å½’åˆ†æ"):
            if independent_vars:
                if regression_type == "çº¿æ€§å›å½’":
                    result = statistical_analyzer.linear_regression_analysis(
                        df, dependent_var, independent_vars
                    )
                else:  # é€»è¾‘å›å½’
                    result = statistical_analyzer.logistic_regression_analysis(
                        df, dependent_var, independent_vars
                    )
                
                if 'error' not in result:
                    st.write(f"**{regression_type}ç»“æœ:**")
                    
                    # æ˜¾ç¤ºæ¨¡å‹æ‘˜è¦
                    st.text(str(result['model_summary']))
                    
                    # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
                    if regression_type == "çº¿æ€§å›å½’":
                        st.write(f"- RÂ²: {result['r_squared']:.4f}")
                        st.write(f"- è°ƒæ•´RÂ²: {result['adjusted_r_squared']:.4f}")
                    else:
                        st.write(f"- ä¼ªRÂ²: {result['pseudo_r_squared']:.4f}")
                        st.write(f"- AIC: {result['aic']:.4f}")
                        
                        # æ˜¾ç¤ºORå€¼
                        st.write("**æ¯”å€¼æ¯” (OR) åŠç½®ä¿¡åŒºé—´:**")
                        or_results = pd.DataFrame({
                            'OR': result['odds_ratios'],
                            'CI_lower': result['or_confidence_intervals'].iloc[:, 0],
                            'CI_upper': result['or_confidence_intervals'].iloc[:, 1],
                            'p_value': result['p_values']
                        })
                        st.dataframe(or_results.round(4))
                else:
                    st.error(result['error'])
            else:
                st.warning("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªè‡ªå˜é‡")

def show_model_interpretation(df):
    """æ˜¾ç¤ºæ¨¡å‹è§£é‡ŠåŠŸèƒ½"""
    st.markdown('<h2 class="sub-header">ğŸ” æ¨¡å‹è§£é‡Š</h2>', unsafe_allow_html=True)
    
    if not st.session_state.get('model_trained', False):
        st.warning("è¯·å…ˆåœ¨æœºå™¨å­¦ä¹ é¡µé¢è®­ç»ƒä¸€ä¸ªæ¨¡å‹")
        return
    
    model = st.session_state.trained_model
    task_type = st.session_state.task_type
    algorithm_name = st.session_state.algorithm_name
    
    if task_type == "èšç±»":
        st.info("èšç±»æ¨¡å‹çš„è§£é‡ŠåŠŸèƒ½æœ‰é™")
        return
    
    X_train = st.session_state.X_train
    X_test = st.session_state.X_test
    y_test = st.session_state.y_test
    feature_names = X_train.columns.tolist()
    
    st.subheader("ğŸ¯ æ¨¡å‹è§£é‡Šæ–¹æ³•")
    
    interpretation_method = st.selectbox(
        "é€‰æ‹©è§£é‡Šæ–¹æ³•",
        ["SHAPåˆ†æ", "æ’åˆ—é‡è¦æ€§", "å±€éƒ¨è§£é‡Š", "å†³ç­–æ ‘è§„åˆ™"]
    )
    
    if interpretation_method == "SHAPåˆ†æ":
        st.subheader("ğŸ” SHAP (SHapley Additive exPlanations) åˆ†æ")
        
        # ç¡®å®šæ¨¡å‹ç±»å‹
        model_type = "tree"
        if algorithm_name in ["Logistic Regression", "Linear Regression", "Elastic Net"]:
            model_type = "linear"
        elif algorithm_name in ["SVM", "SVR", "MLP Neural Network"]:
            model_type = "kernel"
        
        if st.button("è¿è¡ŒSHAPåˆ†æ"):
            with st.spinner("æ­£åœ¨è®¡ç®—SHAPå€¼..."):
                success, message = model_interpreter.explain_model_shap(
                    model, X_train, X_test, model_type
                )
                
                if success:
                    st.success(message)
                    
                    # SHAPç‰¹å¾é‡è¦æ€§æ±‡æ€»
                    st.subheader("ğŸ“Š ç‰¹å¾é‡è¦æ€§æ±‡æ€»")
                    importance_df = model_interpreter.plot_shap_summary(feature_names)
                    
                    # SHAPä¾èµ–å›¾
                    st.subheader("ğŸ“ˆ SHAPä¾èµ–å›¾")
                    feature_idx = st.selectbox(
                        "é€‰æ‹©ç‰¹å¾",
                        range(len(feature_names)),
                        format_func=lambda x: feature_names[x]
                    )
                    model_interpreter.plot_shap_dependence(feature_idx, feature_names, X_test)
                    
                    # å•æ ·æœ¬SHAPç€‘å¸ƒå›¾
                    st.subheader("ğŸŒŠ å•æ ·æœ¬SHAPç€‘å¸ƒå›¾")
                    sample_idx = st.slider("é€‰æ‹©æ ·æœ¬", 0, len(X_test)-1, 0)
                    model_interpreter.plot_shap_waterfall(sample_idx, feature_names)
                    
                else:
                    st.error(message)
    
    elif interpretation_method == "æ’åˆ—é‡è¦æ€§":
        st.subheader("ğŸ”„ æ’åˆ—é‡è¦æ€§åˆ†æ")
        
        n_repeats = st.slider("é‡å¤æ¬¡æ•°", 5, 20, 10)
        
        if st.button("è¿è¡Œæ’åˆ—é‡è¦æ€§åˆ†æ"):
            with st.spinner("æ­£åœ¨è®¡ç®—æ’åˆ—é‡è¦æ€§..."):
                importance_df = model_interpreter.permutation_importance_analysis(
                    model, X_test, y_test, feature_names, n_repeats
                )
                
                if importance_df is not None:
                    st.subheader("ğŸ“‹ æ’åˆ—é‡è¦æ€§ç»“æœ")
                    st.dataframe(importance_df.sort_values('importance_mean', ascending=False))
    
    elif interpretation_method == "å±€éƒ¨è§£é‡Š":
        st.subheader("ğŸ¯ å•æ ·æœ¬å±€éƒ¨è§£é‡Š")
        
        sample_idx = st.slider("é€‰æ‹©æ ·æœ¬ç´¢å¼•", 0, len(X_test)-1, 0)
        
        # ç¡®å®šæ¨¡å‹ç±»å‹
        model_type = "tree"
        if algorithm_name in ["Logistic Regression", "Linear Regression", "Elastic Net"]:
            model_type = "linear"
        elif algorithm_name in ["SVM", "SVR", "MLP Neural Network"]:
            model_type = "kernel"
        
        if st.button("ç”Ÿæˆå±€éƒ¨è§£é‡Š"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆå±€éƒ¨è§£é‡Š..."):
                explanation = model_interpreter.local_explanation(
                    model, X_test, sample_idx, feature_names, model_type
                )
                
                if explanation:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("ğŸ“Š æ ·æœ¬ä¿¡æ¯")
                        st.write(f"**é¢„æµ‹ç»“æœ**: {explanation['prediction']}")
                        
                        if explanation['prediction_proba'] is not None:
                            if len(explanation['prediction_proba']) == 2:
                                st.write(f"**é¢„æµ‹æ¦‚ç‡**: {explanation['prediction_proba'][1]:.4f}")
                            else:
                                st.write("**é¢„æµ‹æ¦‚ç‡**:")
                                for i, prob in enumerate(explanation['prediction_proba']):
                                    st.write(f"  ç±»åˆ« {i}: {prob:.4f}")
                        
                        st.subheader("ğŸ“‹ æ ·æœ¬ç‰¹å¾å€¼")
                        st.dataframe(explanation['sample_data'].T, use_container_width=True)
                    
                    with col2:
                        st.subheader("ğŸ” ç‰¹å¾è´¡çŒ®åº¦")
                        explanation_df = explanation['explanation']
                        
                        # å¯è§†åŒ–ç‰¹å¾è´¡çŒ®
                        fig = px.bar(
                            explanation_df.head(10),
                            x='shap_value',
                            y='feature',
                            orientation='h',
                            title='Top 10 ç‰¹å¾è´¡çŒ®åº¦',
                            color='shap_value',
                            color_continuous_scale='RdBu_r'
                        )
                        st.plotly_chart(fig, use_container_width=True)
                        
                        st.dataframe(explanation_df, use_container_width=True)
    
    elif interpretation_method == "å†³ç­–æ ‘è§„åˆ™":
        st.subheader("ğŸŒ³ å†³ç­–æ ‘è§„åˆ™è§£é‡Š")
        
        if "Tree" in algorithm_name or "Forest" in algorithm_name:
            max_depth = st.slider("æ˜¾ç¤ºæ·±åº¦", 1, 10, 3)
            
            if st.button("æå–å†³ç­–è§„åˆ™"):
                rules = model_interpreter.explain_tree_model(model, feature_names, max_depth)
                
                st.subheader("ğŸ“œ å†³ç­–è§„åˆ™")
                st.text(rules)
        else:
            st.info("è¯¥è§£é‡Šæ–¹æ³•ä»…é€‚ç”¨äºåŸºäºæ ‘çš„æ¨¡å‹")
    
    # æ¨¡å‹æ€§èƒ½æ€»ç»“
    st.divider()
    st.subheader("ğŸ“ˆ æ¨¡å‹æ€§èƒ½æ€»ç»“")
    
    if task_type == "åˆ†ç±»":
        from sklearn.metrics import classification_report
        y_pred = model.predict(X_test)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.text("åˆ†ç±»æŠ¥å‘Š:")
            report = classification_report(y_test, y_pred)
            st.text(report)
        
        with col2:
            # æ··æ·†çŸ©é˜µ
            model_visualizer.plot_confusion_matrix(y_test, y_pred)
    
    elif task_type == "å›å½’":
        from sklearn.metrics import mean_squared_error, r2_score
        y_pred = model.predict(X_test)
        
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("å‡æ–¹è¯¯å·® (MSE)", f"{mse:.4f}")
        with col2:
            st.metric("RÂ² åˆ†æ•°", f"{r2:.4f}")
        
        # å›å½’ç»“æœå¯è§†åŒ–
        model_visualizer.plot_regression_results(y_test, y_pred)

if __name__ == "__main__":
    main()

